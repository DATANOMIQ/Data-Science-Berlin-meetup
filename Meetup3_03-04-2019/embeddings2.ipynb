{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word embeddings are dense vector representations (no 0's).\n",
    "In contrast to sparse representations, like bag of words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick bag of words intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets say you have a vocabulary of size $V$, then for every word you have sparse vector of size $V$ that is 1 at a unique position and zero otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disadvantages of bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It ignores the context\n",
    "- Does not encode similarity between words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, it is used by word2vec to calculate the vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-04T09:24:44.188214Z",
     "start_time": "2019-04-04T09:24:40.673135Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aakas\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "import string\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, Dense\n",
    "from tensorflow.layers import Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import fnmatch\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.set_printoptions(threshold=1800)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Consists of 2225 documents from the BBC news website corresponding to stories in five topical areas from 2004-2005.\n",
    "- Class Labels: 5 (business, entertainment, politics, sport, tech)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Get_the_data](http://mlg.ucd.ie/datasets/bbc.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and label the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-04T09:25:39.309205Z",
     "start_time": "2019-04-04T09:25:38.949329Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business 510\n",
      "entertainment 386\n",
      "tech 401\n",
      "sport 511\n",
      "politics 417\n",
      "Total number of news: 2225\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "news = []\n",
    "num_per_topic = {}\n",
    "for label_type in ['business', 'entertainment', 'tech', 'sport', 'politics']:\n",
    "    dir_name = './bbc/' + label_type\n",
    "    num_per_topic[label_type] = len(fnmatch.filter(os.listdir(dir_name), '*.txt'))\n",
    "    print(label_type, num_per_topic[label_type])\n",
    "    for fname in os.listdir(dir_name):\n",
    "        if fname[-4:] == '.txt':\n",
    "            f = open(os.path.join(dir_name, fname), encoding='utf-8', errors='ignore')\n",
    "            news.append(f.read())\n",
    "            f.close()\n",
    "        if label_type == 'business':\n",
    "            labels.append(0)\n",
    "        elif label_type == 'entertainment':\n",
    "            labels.append(1)\n",
    "        elif label_type == 'tech':\n",
    "            labels.append(2)\n",
    "        elif label_type == 'sport':\n",
    "            labels.append(3)\n",
    "        elif label_type == 'politics':\n",
    "            labels.append(4)\n",
    "print('Total number of news:', len(news))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-04T09:26:03.343239Z",
     "start_time": "2019-04-04T09:26:03.339249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yukos unit buyer faces loan claim\n",
      "\n",
      "The owners of embattled Russian oil giant Yukos are to ask the buyer of its former production unit to pay back a $900m (£479m) loan.\n",
      "\n",
      "State-owned Rosneft bought the Yugansk unit for $9.3bn in a sale forced by Russia to part settle a $27.5bn tax claim against Yukos. Yukos' owner Menatep Group says it will ask Rosneft to repay a loan that Yugansk had secured on its assets. Rosneft already faces a similar $540m repayment demand from foreign banks. Legal experts said Rosneft's purchase of Yugansk would include such obligations. \"The pledged assets are with Rosneft, so it will have to pay real money to the creditors to avoid seizure of Yugansk assets,\" said Moscow-based US lawyer Jamie Firestone, who is not connected to the case. Menatep Group's managing director Tim Osborne told the Reuters news agency: \"If they default, we will fight them where the rule of law exists under the international arbitration clauses of the credit.\"\n",
      "\n",
      "Rosneft officials were unavailable for comment. But the company has said it intends to take action against Menatep to recover some of the tax claims and debts owed by Yugansk. Yukos had filed for bankruptcy protection in a US court in an attempt to prevent the forced sale of its main production arm. The sale went ahead in December and Yugansk was sold to a little-known shell company which in turn was bought by Rosneft. Yukos claims its downfall was punishment for the political ambitions of its founder Mikhail Khodorkovsky and has vowed to sue any participant in the sale.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(news[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If stopwords were not downloaded before uncommment and run\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process data for embedding matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ad sales boost Time Warner profit\n",
      "\n",
      "Quarterly profits at US media giant TimeWarner jumped 76 to 113bn £600m for the three months to December from 639m yearearlier\n",
      "\n",
      "The firm which is now one of the biggest investors in Google benefited from sales of highspeed internet connections and higher advert sales TimeWarner said fourth quarter sales rose 2 to 111bn from 109bn Its profits were buoyed by oneoff gains which offset a profit dip at Warner Bros and less users for AOL\n",
      "\n",
      "Time Warner said on Friday that it now owns 8 of searchengine Google But its own internet business AOL had has mixed fortunes It lost 464000 subscribers in the fourth quarter profits were lower than in the preceding three quarters However the company said AOLs underlying profit before exceptional items rose 8 on the back of stronger internet advertising revenues It hopes to increase subscribers by offering the online service free to TimeWarner internet customers and will try to sign up AOLs existing customers for highspeed broadband TimeWarner also has to restate 2000 and 2003 results following a probe by the US Securities Exchange Commission SEC which is close to concluding\n",
      "\n",
      "Time Warners fourth quarter profits were slightly better than analysts expectations But its film division saw profits slump 27 to 284m helped by boxoffice flops Alexander and Catwoman a sharp contrast to yearearlier when the third and final film in the Lord of the Rings trilogy boosted results For the fullyear TimeWarner posted a profit of 336bn up 27 from its 2003 performance while revenues grew 64 to 4209bn Our financial performance was strong meeting or exceeding all of our fullyear objectives and greatly enhancing our flexibility chairman and chief executive Richard Parsons said For 2005 TimeWarner is projecting operating earnings growth of around 5 and also expects higher revenue and wider profit margins\n",
      "\n",
      "TimeWarner is to restate its accounts as part of efforts to resolve an inquiry into AOL by US market regulators It has already offered to pay 300m to settle charges in a deal that is under review by the SEC The company said it was unable to estimate the amount it needed to set aside for legal reserves which it previously set at 500m It intends to adjust the way it accounts for a deal with German music publisher Bertelsmanns purchase of a stake in AOL Europe which it had reported as advertising revenue It will now book the sale of its stake in AOL Europe as a loss on the value of that stake\n",
      "\n"
     ]
    }
   ],
   "source": [
    "translator = str.maketrans('', '', string.punctuation)\n",
    "news = [new.translate(translator) for new in news]\n",
    "print(news[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ad sales boost Time Warner profit\n",
      "\n",
      "Quarterly profits at US media giant TimeWarner jumped  to bn £m for the three months to December from m yearearlier\n",
      "\n",
      "The firm which is now one of the biggest investors in Google benefited from sales of highspeed internet connections and higher advert sales TimeWarner said fourth quarter sales rose  to bn from bn Its profits were buoyed by oneoff gains which offset a profit dip at Warner Bros and less users for AOL\n",
      "\n",
      "Time Warner said on Friday that it now owns  of searchengine Google But its own internet business AOL had has mixed fortunes It lost  subscribers in the fourth quarter profits were lower than in the preceding three quarters However the company said AOLs underlying profit before exceptional items rose  on the back of stronger internet advertising revenues It hopes to increase subscribers by offering the online service free to TimeWarner internet customers and will try to sign up AOLs existing customers for highspeed broadband TimeWarner also has to restate  and  results following a probe by the US Securities Exchange Commission SEC which is close to concluding\n",
      "\n",
      "Time Warners fourth quarter profits were slightly better than analysts expectations But its film division saw profits slump  to m helped by boxoffice flops Alexander and Catwoman a sharp contrast to yearearlier when the third and final film in the Lord of the Rings trilogy boosted results For the fullyear TimeWarner posted a profit of bn up  from its  performance while revenues grew  to bn Our financial performance was strong meeting or exceeding all of our fullyear objectives and greatly enhancing our flexibility chairman and chief executive Richard Parsons said For  TimeWarner is projecting operating earnings growth of around  and also expects higher revenue and wider profit margins\n",
      "\n",
      "TimeWarner is to restate its accounts as part of efforts to resolve an inquiry into AOL by US market regulators It has already offered to pay m to settle charges in a deal that is under review by the SEC The company said it was unable to estimate the amount it needed to set aside for legal reserves which it previously set at m It intends to adjust the way it accounts for a deal with German music publisher Bertelsmanns purchase of a stake in AOL Europe which it had reported as advertising revenue It will now book the sale of its stake in AOL Europe as a loss on the value of that stake\n",
      "\n"
     ]
    }
   ],
   "source": [
    "news = [re.sub(r'\\d+', '', new) for new in news]\n",
    "print(news[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lower words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ad sales boost time warner profit\n",
      "\n",
      "quarterly profits at us media giant timewarner jumped  to bn £m for the three months to december from m yearearlier\n",
      "\n",
      "the firm which is now one of the biggest investors in google benefited from sales of highspeed internet connections and higher advert sales timewarner said fourth quarter sales rose  to bn from bn its profits were buoyed by oneoff gains which offset a profit dip at warner bros and less users for aol\n",
      "\n",
      "time warner said on friday that it now owns  of searchengine google but its own internet business aol had has mixed fortunes it lost  subscribers in the fourth quarter profits were lower than in the preceding three quarters however the company said aols underlying profit before exceptional items rose  on the back of stronger internet advertising revenues it hopes to increase subscribers by offering the online service free to timewarner internet customers and will try to sign up aols existing customers for highspeed broadband timewarner also has to restate  and  results following a probe by the us securities exchange commission sec which is close to concluding\n",
      "\n",
      "time warners fourth quarter profits were slightly better than analysts expectations but its film division saw profits slump  to m helped by boxoffice flops alexander and catwoman a sharp contrast to yearearlier when the third and final film in the lord of the rings trilogy boosted results for the fullyear timewarner posted a profit of bn up  from its  performance while revenues grew  to bn our financial performance was strong meeting or exceeding all of our fullyear objectives and greatly enhancing our flexibility chairman and chief executive richard parsons said for  timewarner is projecting operating earnings growth of around  and also expects higher revenue and wider profit margins\n",
      "\n",
      "timewarner is to restate its accounts as part of efforts to resolve an inquiry into aol by us market regulators it has already offered to pay m to settle charges in a deal that is under review by the sec the company said it was unable to estimate the amount it needed to set aside for legal reserves which it previously set at m it intends to adjust the way it accounts for a deal with german music publisher bertelsmanns purchase of a stake in aol europe which it had reported as advertising revenue it will now book the sale of its stake in aol europe as a loss on the value of that stake\n",
      "\n"
     ]
    }
   ],
   "source": [
    "news = [new.lower() for new in news]\n",
    "print(news[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stop-words (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ad sales boost time warner profit quarterly profits us media giant timewarner jumped bn £m three months december yearearlier firm one biggest investors google benefited sales highspeed internet connections higher advert sales timewarner said fourth quarter sales rose bn bn profits buoyed oneoff gains offset profit dip warner bros less users aol time warner said friday owns searchengine google internet business aol mixed fortunes lost subscribers fourth quarter profits lower preceding three quarters however company said aols underlying profit exceptional items rose back stronger internet advertising revenues hopes increase subscribers offering online service free timewarner internet customers try sign aols existing customers highspeed broadband timewarner also restate results following probe us securities exchange commission sec close concluding time warners fourth quarter profits slightly better analysts expectations film division saw profits slump helped boxoffice flops alexander catwoman sharp contrast yearearlier third final film lord rings trilogy boosted results fullyear timewarner posted profit bn performance revenues grew bn financial performance strong meeting exceeding fullyear objectives greatly enhancing flexibility chairman chief executive richard parsons said timewarner projecting operating earnings growth around also expects higher revenue wider profit margins timewarner restate accounts part efforts resolve inquiry aol us market regulators already offered pay settle charges deal review sec company said unable estimate amount needed set aside legal reserves previously set intends adjust way accounts deal german music publisher bertelsmanns purchase stake aol europe reported advertising revenue book sale stake aol europe loss value stake\n"
     ]
    }
   ],
   "source": [
    "en_stop_words = set(stopwords.words('english'))\n",
    "loop_int = 0\n",
    "for new in news:\n",
    "    news[loop_int] = ' '.join([word for word in news[loop_int].split() if word not in en_stop_words])\n",
    "    loop_int += 1\n",
    "print(news[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatize words (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ad sale boost time warner profit quarterly profit u medium giant timewarner jumped bn £m three month december yearearlier firm one biggest investor google benefited sale highspeed internet connection higher advert sale timewarner said fourth quarter sale rose bn bn profit buoyed oneoff gain offset profit dip warner bros le user aol time warner said friday owns searchengine google internet business aol mixed fortune lost subscriber fourth quarter profit lower preceding three quarter however company said aols underlying profit exceptional item rose back stronger internet advertising revenue hope increase subscriber offering online service free timewarner internet customer try sign aols existing customer highspeed broadband timewarner also restate result following probe u security exchange commission sec close concluding time warner fourth quarter profit slightly better analyst expectation film division saw profit slump helped boxoffice flop alexander catwoman sharp contrast yearearlier third final film lord ring trilogy boosted result fullyear timewarner posted profit bn performance revenue grew bn financial performance strong meeting exceeding fullyear objective greatly enhancing flexibility chairman chief executive richard parson said timewarner projecting operating earnings growth around also expects higher revenue wider profit margin timewarner restate account part effort resolve inquiry aol u market regulator already offered pay settle charge deal review sec company said unable estimate amount needed set aside legal reserve previously set intends adjust way account deal german music publisher bertelsmanns purchase stake aol europe reported advertising revenue book sale stake aol europe loss value stake\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "loop_int = 0\n",
    "for new in news:\n",
    "    news[loop_int] = ' '.join([lemmatizer.lemmatize(word) for word in news[loop_int].split()])\n",
    "    loop_int += 1\n",
    "print(news[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into train and test set with topics approximately evenly distributed between both data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stshsp = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in stshsp.split(news, labels):\n",
    "    x_train = np.array(news)[train_index.astype(int)]\n",
    "    y_train = np.array(labels)[train_index.astype(int)]\n",
    "    x_test = np.array(news)[test_index.astype(int)]\n",
    "    y_test = np.array(labels)[test_index.astype(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'warning junk mail deluge amount spam circulating online could undergo massive increase say expert antispam group spamhaus warning novel virus hide origin junk mail program make spam look like sent legitimate mail server making hard spot filter spamhaus said problem went unchecked real email message could get drowned sheer amount junk sent many spammer recruited home pc act anonymous email relay attempt hide origin junk mail pc recruited using virus worm compromise machine via known vulnerability tricking people opening attachment infected malicious program compromised machine start pump junk mail behalf spammer spamhaus help block junk message machine collecting circulating blacklist net address known harbour infected machine novel worm spotted recently spamhaus route junk via mail server net service firm infected machine used get online first place way junk mail get net address look legitimate blocking mail net firm catch spam impractical spamhaus worried technique give junk mailer ability spam little fear spotted stopped steve linford director spamhaus predicted lot spammer exploit technique could trigger failure net email sending infrastructure david stanley uk managing director filtering firm ciphertrust said new technique next logical step spammer adding armoury said amount spam circulation still growing said mr stanley think appearance trick would mean email meltdown kevin hogan senior manager symantec security response said warning premature something like mean end email email would stopped twothree year ago said mr hogan technique routing mail via mail server net service firm might cause problem use blacklist block list mean technique stopping spam lost efficacy mr hogan said junk mail filtered symantec subsidiary brightmail spotted using technique rely looking net address instance said mr hogan filtering email message contain web link stop spam'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only the 1000 most frequently occuring words are considered  \n",
    "max_num_words = 1000\n",
    "\n",
    "# instantiate Tokenizer\n",
    "tokenizer = Tokenizer(num_words=max_num_words)\n",
    "\n",
    "# fit Tokenizer to processed text data assigning a unique integer to the 1000 most freqeuently occuring words\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "# transform news and assign the transformation to sequences\n",
    "train_sequences = tokenizer.texts_to_sequences(x_train)\n",
    "test_sequences = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "dummy_y_train = np_utils.to_categorical(y_train)\n",
    "dummy_y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[571, 493, 630, 571, 630, 802, 323, 148, 309, 285]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sequences[0][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = len(max(train_sequences, key=len)) if len(max(train_sequences, key=len)) > len(max(test_sequences, key=len)) \\\n",
    "else len(max(test_sequences, key=len))\n",
    "train_pad_sequ = pad_sequences(train_sequences, maxlen=max_len, padding='post')\n",
    "test_pad_sequ = pad_sequences(test_sequences, maxlen=max_len, padding='post')\n",
    "\n",
    "#labels = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([571, 493, 630, 571, 630, 802, 323, 148, 309, 285, 603, 630,  13,\n",
       "        29, 185, 736,  15, 189, 773, 493, 387, 493,  84,   1, 249, 411,\n",
       "       131,  29, 571,   7, 524, 494, 387,  46, 457, 941,  46, 127, 630,\n",
       "        17,   7, 239, 362, 309,  19, 666, 863, 493,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pad_sequ[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1147"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 Billion tokens from a Wikipedia dump from 2015 and Gigaword5.\n",
    "The 400000 most occuring words are then chosen and their co-occurence matrix is constructed\n",
    "If a word appears $d$ words apart from another word and $d$ is smaller or equal than the window size then $1/d$ is added to the co-occurence value between those words.\n",
    "\n",
    "The trainig objective of GloVe is to learn word vectors such that their dot product equals the logarithm of the word's probability of co-occurence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](glove.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create co-occurence matrix $X$ of size $(VxV)$, with $V = vocabulary$ with element $X_{ij}$ representing the probability how often word $i$ appears in the context of word $j$.A word is part of another word's context if it appears in its context window. The farer away word $i$ appears in $j$'s context window the lower $X_{ij}$. \n",
    "\n",
    "2. Randomly intiliaze two matrices $W_1$ and $W_2$ both of size $(VxN)$ and two vectors $b_1$ and $b_2$ both of size $(Vx1)$.\n",
    "\n",
    "3. For each word pair $i$ and $j$, pick the corresponding: \n",
    "\n",
    "$w_i^Tw_j + b_i + b_j = log(X_{ij})$, \n",
    "\n",
    "with $w_i$ and $w_j$ of size $(Nx1)$ being updated through the cost function\n",
    "\n",
    "  $J = \\sum_{i=1}^{V} \\sum_{j=i}^{V} f(X_{ij})(w_i^Tw_j + b_i + b_j - log(X_{ij}))^2$\n",
    "\n",
    "where \n",
    "\n",
    "$f(X_{ij}) = (X_{ij}/X_{max})^\\alpha$ if $X_{ij} < X_{max}$ else $1$\n",
    "\n",
    "Finally, add matrices $W_1$ and $W_2$ to receive embedding matrix $W$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Get_the_paper](https://nlp.stanford.edu/pubs/glove.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "file = open('GloVe/glove.6B.300d.txt', encoding='utf-8')\n",
    "for line in file:\n",
    "    vector = line.split()\n",
    "    word = vector[0]\n",
    "    values = np.asarray(vector[1:], dtype='float32')\n",
    "    embeddings_index[word] = values\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.0522e-01, -1.2182e-01,  5.2485e-01,  1.7955e-01, -4.7728e-01,\n",
       "       -2.8371e-01, -1.0358e-01,  3.1730e-01, -7.2417e-01, -1.0331e+00,\n",
       "        2.1992e-01, -2.2033e-01,  4.3517e-01,  3.3936e-01,  4.9328e-01,\n",
       "       -1.2552e-01, -3.3965e-01,  7.4982e-02,  7.0120e-01, -4.3616e-01,\n",
       "        2.7040e-01,  3.9262e-02, -2.6013e-01,  3.5666e-01,  3.5008e-01,\n",
       "       -2.8987e-01, -2.7419e-01,  1.9304e-02, -1.7569e-01,  1.0220e-01,\n",
       "       -9.7804e-01, -5.9894e-01,  3.8760e-02,  3.4257e-01, -5.1110e-01,\n",
       "       -4.2461e-01,  2.2995e-01,  7.4401e-01, -2.9785e-01,  4.8539e-01,\n",
       "        2.7491e-01, -4.0656e-01, -9.5166e-02,  9.0538e-01, -4.4044e-02,\n",
       "        6.5553e-01, -3.9572e-01, -1.5594e-02, -1.2509e-01, -4.6166e-01,\n",
       "       -2.3151e-01,  4.8925e-01, -1.9804e-01, -1.3514e-01,  5.3156e-02,\n",
       "        4.5265e-01,  4.6270e-01, -2.4297e-01, -3.8862e-02, -4.5783e-01,\n",
       "       -3.1181e-01,  1.9102e-01, -2.9440e-01,  3.9846e-01,  9.1296e-02,\n",
       "       -6.3331e-02,  1.0522e+00,  2.5403e-01,  5.3852e-03,  1.2408e-01,\n",
       "        4.0509e-01,  4.2359e-01, -1.3846e-01,  9.7398e-03,  3.3999e-01,\n",
       "        1.1002e+00,  3.3587e-01,  5.4365e-01, -2.9006e-03,  5.9938e-01,\n",
       "       -3.7735e-01,  2.7526e-01, -6.1941e-02, -1.7578e-01,  1.4071e-02,\n",
       "       -8.2355e-02,  2.4953e-01,  2.3700e-01,  4.2400e-01, -1.8230e-01,\n",
       "        2.5833e-01,  3.3985e-01, -3.0343e-01,  1.1669e-01, -2.5165e-02,\n",
       "       -3.9424e-01,  4.5479e-01, -2.0338e-01,  8.4414e-01, -6.8806e-01,\n",
       "        2.6508e-01,  2.7285e-01, -2.6067e-01,  4.9612e-01, -4.9952e-02,\n",
       "        1.1159e-01,  6.9038e-02,  2.8517e-01,  7.4609e-02,  2.4181e-01,\n",
       "        6.5516e-01,  5.5748e-01,  4.1435e-01,  2.0497e-02, -2.3074e-02,\n",
       "       -4.1546e-01, -6.4997e-01, -2.9907e-01, -3.2932e-01, -1.1047e+00,\n",
       "       -4.9364e-01,  4.1066e-01,  3.2437e-01, -1.7446e-01,  3.8359e-02,\n",
       "       -5.9064e-01, -7.0055e-01,  4.1724e-01, -4.7443e-01, -6.4701e-01,\n",
       "       -3.3121e-01, -2.6228e-01, -6.0383e-01, -3.5692e-01, -3.1923e-01,\n",
       "       -2.6894e-01,  5.0134e-02, -1.2960e-02, -5.5560e-01,  1.8601e-01,\n",
       "        1.6446e-01,  1.5782e-01,  2.2450e-01, -2.3730e-01, -8.3337e-02,\n",
       "       -6.4864e-05,  4.7881e-01,  1.9324e-02,  3.9092e-01,  1.2879e-02,\n",
       "        9.0271e-01,  4.6287e-01,  3.4207e-01,  1.8486e-01, -2.5995e-01,\n",
       "       -1.8187e-01, -1.4993e-02,  3.6981e-01,  7.7258e-01, -3.9655e-01,\n",
       "       -2.3408e-01, -1.7631e-01,  1.5438e-01, -5.2437e-01, -2.5052e-01,\n",
       "        8.2036e-01, -3.7149e-01, -5.5132e-01,  7.6091e-02,  1.4137e-03,\n",
       "       -2.2045e-01,  2.2686e-01, -8.0953e-01,  5.6091e-01,  2.6708e-01,\n",
       "        9.7754e-01, -3.2684e-01,  1.6711e-01,  1.5177e-01,  2.4640e-01,\n",
       "       -5.6516e-01,  2.1262e-01,  7.0311e-01, -4.6509e-01, -8.5632e-02,\n",
       "       -1.1259e-01,  2.4247e-01, -2.3660e-01, -1.7594e-01, -2.6983e-01,\n",
       "       -4.5885e-01,  6.6561e-01,  2.6763e-01, -2.0850e-01, -1.1081e-01,\n",
       "        1.3585e-01, -1.1189e-01,  3.2922e-01, -1.6048e-01,  1.2428e-01,\n",
       "        8.2802e-01,  3.8004e-01, -4.3574e-01,  5.7078e-01,  3.8903e-01,\n",
       "        7.3012e-01,  2.1797e-01, -3.3655e-01, -2.2198e-01, -7.3306e-01,\n",
       "        4.3774e-01, -2.4479e-01, -3.0694e-01, -1.6574e-01,  5.8887e-01,\n",
       "        4.4326e-02, -7.9910e-02,  1.4205e-01,  6.1808e-01,  1.9825e-02,\n",
       "        1.3412e-01, -1.8814e-01, -6.3468e-01, -9.3508e-02,  4.7886e-01,\n",
       "        1.4214e-01,  5.3552e-01, -1.5106e-01,  3.8129e-01,  2.7178e-01,\n",
       "        1.4827e-01,  1.2530e-01, -1.8694e-01, -8.4211e-01,  2.6918e-01,\n",
       "        5.0380e-01,  6.2866e-01,  7.7161e-01, -3.4348e-01, -5.9703e-01,\n",
       "       -9.4704e-02, -2.9732e-01,  1.1940e-02, -2.0531e-01,  2.5805e-01,\n",
       "        3.7922e-01, -5.7962e-01, -6.2281e-01,  4.8110e-01,  1.5279e-02,\n",
       "       -4.3655e-02,  7.6838e-02, -3.9987e-01,  2.9332e-01,  1.8823e-01,\n",
       "       -1.0356e-01, -1.4623e-01,  1.5674e-01,  3.1403e-01,  2.6519e-01,\n",
       "        8.4402e-02,  2.8782e-01, -8.7547e-02,  6.7107e-01, -2.1520e-01,\n",
       "       -6.9612e-01,  1.7761e-01, -3.3499e-01,  3.0226e-01,  2.4500e-01,\n",
       "        6.3081e-01,  5.0799e-01, -1.0607e-01, -6.9189e-02, -1.8056e-01,\n",
       "       -2.4694e-01, -1.1409e+00, -1.9770e-02,  6.7076e-01,  5.8608e-01,\n",
       "       -5.0192e-02, -2.0886e-02, -1.7503e-01, -4.0221e-01,  3.9560e-01,\n",
       "       -5.1891e-01, -5.1425e-01, -7.3054e-01, -5.7230e-01,  4.9274e-01,\n",
       "       -3.8920e-01, -1.7881e-01, -2.5104e-02, -4.2733e-01, -5.7263e-01,\n",
       "        3.6636e-01,  5.3747e-02,  1.0656e+00, -6.2223e-02,  4.0953e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index['bbc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the assignment of integers ordered by word frequency among all documents through tokenizer.texts_to_sequences comes in handy. If a word's ranking is smaller than 1000, its embedding-values are not loaded into the embedding matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 300\n",
    "\n",
    "embedding_matrix = np.zeros((max_num_words, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i < max_num_words:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "996"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(np.sum(embedding_matrix, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\arturzeitler\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 1147, 300)         300000    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 344100)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                5505616   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 85        \n",
      "=================================================================\n",
      "Total params: 5,805,701\n",
      "Trainable params: 5,805,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_num_words, output_dim=embedding_dim, weights=[embedding_matrix], \n",
    "                    input_length=max_len, trainable=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\arturzeitler\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "1780/1780 [==============================] - 43s 24ms/sample - loss: 0.8734 - acc: 0.7112s - loss: 0.9039 - acc: 0.69 - ETA: 3s - loss: 0.9019 - acc: 0.6 - ET\n",
      "Epoch 2/5\n",
      "1780/1780 [==============================] - 43s 24ms/sample - loss: 0.3541 - acc: 0.9343\n",
      "Epoch 3/5\n",
      "1780/1780 [==============================] - 42s 24ms/sample - loss: 0.2078 - acc: 0.9646\n",
      "Epoch 4/5\n",
      "1780/1780 [==============================] - 43s 24ms/sample - loss: 0.1342 - acc: 0.9848s - loss: 0.1363 - \n",
      "Epoch 5/5\n",
      "1780/1780 [==============================] - 42s 24ms/sample - loss: 0.1104 - acc: 0.9899\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d36d3a0cf8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_pad_sequ, dummy_y_train,\n",
    "            epochs=5,\n",
    "            batch_size=4)\n",
    "#model.save_weights('tuned_glove_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_pad_sequ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(445, 5)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.950561797752809"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(dummy_y_test, (predictions > 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec & gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Randomly initialize matrix $W_1$ of size $(VxN)$ and matrix $W_2$ of size $(NxV)$.\n",
    "\n",
    "2. Each word in the voabulary $V$ is represented as a unique one hot encoded vector $X_i$. \n",
    "\n",
    "3. A supervised learning problem is created given the one-hot vectors of the context window as input and the one hot vector of the chosen word as target. The output is vector containing the probability of each word in vocabulary given the input words.\n",
    "\n",
    "4. The weights are adjusted through backpropagation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](word2vec-cbow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Get_the_other_paper](https://arxiv.org/pdf/1301.3781.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gensim is a production-ready open-source library for unsupervised topic modeling and natural language processing, using modern statistical machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format('word2vec\\GoogleNews-vectors-negative300.bin', binary=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.06494141  0.08544922 -0.10644531  0.41015625  0.125       0.01977539\n",
      "  0.06982422 -0.08642578 -0.03686523  0.05908203 -0.16308594 -0.39648438\n",
      " -0.28125    -0.07519531  0.04345703  0.22753906  0.1796875   0.33203125\n",
      "  0.23339844 -0.09423828 -0.29492188  0.11279297  0.203125    0.33398438\n",
      "  0.00787354  0.4453125  -0.20507812  0.40234375  0.30078125 -0.08496094\n",
      "  0.00334167  0.21484375  0.10107422 -0.19726562 -0.3515625  -0.1796875\n",
      " -0.3671875   0.4765625  -0.00148773 -0.12597656  0.23339844 -0.29882812\n",
      "  0.08203125  0.35351562  0.02416992  0.26953125 -0.13476562 -0.25585938\n",
      " -0.40429688 -0.19726562 -0.23925781 -0.14453125  0.5390625  -0.07324219\n",
      " -0.08691406 -0.38671875 -0.4296875   0.15527344 -0.2734375  -0.16015625\n",
      "  0.22265625  0.06445312 -0.26367188 -0.18066406  0.17285156 -0.04492188\n",
      " -0.13378906 -0.2890625  -0.35742188 -0.18457031 -0.21484375  0.23535156\n",
      " -0.12207031  0.02636719 -0.24902344 -0.04418945  0.31054688 -0.20605469\n",
      "  0.14160156 -0.24023438  0.05859375  0.38867188 -0.00866699 -0.20996094\n",
      "  0.07861328  0.22460938  0.02514648  0.0112915  -0.10546875  0.10400391\n",
      " -0.08056641 -0.01544189 -0.08398438  0.11035156  0.04003906  0.23242188\n",
      " -0.2265625  -0.2578125   0.24902344  0.02258301 -0.1875      0.25195312\n",
      " -0.04663086  0.12890625 -0.14160156  0.51171875 -0.3203125   0.19921875\n",
      "  0.12597656 -0.43164062 -0.03125    -0.20605469  0.04150391  0.02807617\n",
      "  0.32226562  0.15429688  0.06738281 -0.39453125  0.27734375  0.13085938\n",
      " -0.18945312 -0.17578125 -0.19042969  0.02880859  0.03393555 -0.08789062\n",
      " -0.10009766  0.24121094  0.1796875  -0.2890625  -0.31445312 -0.12304688\n",
      " -0.06079102  0.10351562 -0.125       0.10009766 -0.25976562 -0.02087402\n",
      "  0.49804688 -0.06103516  0.33984375 -0.03588867 -0.1875      0.171875\n",
      "  0.16699219 -0.28515625 -0.05297852 -0.20605469 -0.09912109 -0.19433594\n",
      "  0.19726562 -0.18847656 -0.07275391 -0.46484375  0.07080078 -0.2734375\n",
      "  0.15332031  0.33007812 -0.2109375   0.0168457  -0.38085938  0.49414062\n",
      " -0.09179688  0.11914062 -0.04492188 -0.46289062  0.0612793   0.05615234\n",
      " -0.1796875   0.05175781 -0.48046875  0.03930664 -0.00198364 -0.296875\n",
      "  0.2734375   0.03564453  0.5        -0.53125     0.20410156 -0.13769531\n",
      "  0.23632812 -0.18652344 -0.22460938 -0.5234375   0.16210938  0.296875\n",
      " -0.12695312  0.25390625 -0.01055908 -0.02770996 -0.24121094  0.18164062\n",
      " -0.18457031 -0.14160156  0.09179688  0.08691406 -0.2578125   0.12890625\n",
      " -0.24609375  0.06933594 -0.20703125  0.2578125  -0.23828125 -0.12890625\n",
      " -0.03833008  0.0111084   0.16210938  0.20214844 -0.17773438  0.32617188\n",
      "  0.04272461 -0.25195312 -0.25        0.04663086 -0.17675781 -0.12792969\n",
      "  0.09814453 -0.19628906 -0.36523438 -0.18164062 -0.29296875 -0.00933838\n",
      "  0.32421875  0.26171875 -0.2734375   0.11523438  0.04248047  0.05566406\n",
      "  0.4609375  -0.0546875   0.08154297 -0.33203125  0.13183594 -0.18164062\n",
      " -0.15234375  0.17480469  0.55859375  0.16210938  0.12890625  0.26171875\n",
      "  0.08935547  0.07080078  0.26171875 -0.17480469 -0.13183594  0.21289062\n",
      " -0.16503906 -0.03015137  0.00238037  0.18945312  0.23535156 -0.08007812\n",
      " -0.06738281 -0.08251953  0.24609375 -0.20996094 -0.3125      0.06176758\n",
      "  0.48828125 -0.13867188  0.25390625  0.12451172  0.18164062  0.0078125\n",
      "  0.06030273 -0.0177002  -0.19140625  0.00558472  0.33203125 -0.25\n",
      " -0.09960938  0.03015137 -0.19140625  0.01287842  0.18847656  0.31640625\n",
      "  0.03173828 -0.07568359 -0.10302734  0.45117188 -0.31640625  0.40234375\n",
      "  0.06054688  0.04345703  0.27148438 -0.3046875  -0.06835938 -0.08642578\n",
      " -0.08154297  0.18164062 -0.10400391  0.05615234  0.03222656  0.10351562\n",
      "  0.12890625 -0.15917969 -0.15722656  0.06884766 -0.1796875   0.25976562]\n"
     ]
    }
   ],
   "source": [
    "embedd = model.wv['bbc']\n",
    "print(embedd)\n",
    "#ind = model.wv.vocab.get('the').index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((max_num_words, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i < max_num_words:\n",
    "        try:\n",
    "            embedding_vector = model.wv[word]\n",
    "        except KeyError:\n",
    "            embedding_vector = None\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "989"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(np.sum(embedding_matrix, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 1147, 300)         300000    \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 344100)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                5505616   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 85        \n",
      "=================================================================\n",
      "Total params: 5,805,701\n",
      "Trainable params: 5,805,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_num_words, output_dim=embedding_dim, weights=[embedding_matrix], \n",
    "                    input_length=max_len, trainable=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1780/1780 [==============================] - 33s 18ms/sample - loss: 0.4272 - acc: 0.8461\n",
      "Epoch 2/5\n",
      "1780/1780 [==============================] - 31s 17ms/sample - loss: 0.0126 - acc: 0.9978s - loss: \n",
      "Epoch 3/5\n",
      "1780/1780 [==============================] - 31s 18ms/sample - loss: 7.5907e-04 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "1780/1780 [==============================] - 33s 18ms/sample - loss: 4.0240e-04 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "1780/1780 [==============================] - 33s 18ms/sample - loss: 2.8878e-04 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23d083d7dd8>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_pad_sequ, dummy_y_train,\n",
    "            epochs=5,\n",
    "            batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_pad_sequ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9573033707865168"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(dummy_y_test, (predictions > 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to train word2vec on your own text corpus with gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = gensim.models.Word2Vec(min_count=4, size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = [new.split() for new in x_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['collins',\n",
       " 'appeal',\n",
       " 'drug',\n",
       " 'ban',\n",
       " 'sprinter',\n",
       " 'michelle',\n",
       " 'collins',\n",
       " 'lodged',\n",
       " 'appeal',\n",
       " 'eightyear',\n",
       " 'doping',\n",
       " 'ban',\n",
       " 'north',\n",
       " 'american',\n",
       " 'court',\n",
       " 'arbitration',\n",
       " 'sport',\n",
       " 'ca',\n",
       " 'yearold',\n",
       " 'received',\n",
       " 'ban',\n",
       " 'last',\n",
       " 'month',\n",
       " 'result',\n",
       " 'connection',\n",
       " 'federal',\n",
       " 'inquiry',\n",
       " 'balco',\n",
       " 'doping',\n",
       " 'scandal',\n",
       " 'first',\n",
       " 'athlete',\n",
       " 'banned',\n",
       " 'without',\n",
       " 'positive',\n",
       " 'drug',\n",
       " 'test',\n",
       " 'admission',\n",
       " 'drug',\n",
       " 'use',\n",
       " 'ca',\n",
       " 'said',\n",
       " 'ruling',\n",
       " 'normally',\n",
       " 'given',\n",
       " 'within',\n",
       " 'four',\n",
       " 'month',\n",
       " 'appeal',\n",
       " 'collins',\n",
       " 'suspended',\n",
       " 'u',\n",
       " 'antidoping',\n",
       " 'agency',\n",
       " 'based',\n",
       " 'pattern',\n",
       " 'observed',\n",
       " 'blood',\n",
       " 'urine',\n",
       " 'test',\n",
       " 'well',\n",
       " 'evidence',\n",
       " 'balco',\n",
       " 'investigation',\n",
       " 'well',\n",
       " 'hit',\n",
       " 'ban',\n",
       " 'collins',\n",
       " 'stripped',\n",
       " 'world',\n",
       " 'u',\n",
       " 'indoor',\n",
       " 'title',\n",
       " 'san',\n",
       " 'franciscobased',\n",
       " 'balco',\n",
       " 'laboratory',\n",
       " 'centre',\n",
       " 'scandal',\n",
       " 'rocked',\n",
       " 'sport',\n",
       " 'company',\n",
       " 'accused',\n",
       " 'distributing',\n",
       " 'illegal',\n",
       " 'performanceenhancing',\n",
       " 'drug',\n",
       " 'elite',\n",
       " 'athlete']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.build_vocab(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10350944, 11349960)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.train(sent, total_examples=model2.corpus_count, epochs=30, report_delay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.99413025, -0.20194669, -0.42620084,  0.4460835 ,  0.30581605,\n",
       "       -0.4742018 , -0.3601839 ,  0.3225689 , -0.5148598 ,  1.0312783 ,\n",
       "        1.2999033 ,  0.22674341,  0.75039387,  0.44372705,  0.16040012,\n",
       "       -0.62010753, -0.10729679, -0.06170062, -0.09001117,  1.448449  ,\n",
       "        0.02740547, -0.24464263, -0.7453877 , -0.9412458 ,  0.66363484,\n",
       "       -0.09560748, -0.48959064, -0.3056355 ,  0.1496163 , -0.09705112,\n",
       "       -0.00971344,  0.4996164 ,  0.16528675, -0.42980462,  0.25316024,\n",
       "       -0.34875566,  0.5857569 ,  0.01958018, -0.8425177 , -0.26651308,\n",
       "        0.09368241, -0.3635835 ,  0.5704309 , -0.8728141 , -0.19457762,\n",
       "        0.24356344,  0.75698096, -0.06678712,  0.5018418 ,  0.4549258 ,\n",
       "       -1.2295932 , -0.45444015, -0.5253445 ,  0.7744052 ,  0.5649921 ,\n",
       "        0.5480347 ,  0.5309998 , -1.1545534 , -1.2731216 ,  0.10626012,\n",
       "       -0.06009358, -0.8233754 , -0.675419  ,  0.23779693, -0.22993396,\n",
       "       -0.8960414 , -0.9856039 ,  0.24893601, -0.22650301,  0.04390133,\n",
       "        0.41564077, -0.6028698 , -0.47901407, -0.8212744 ,  0.1756597 ,\n",
       "        0.6290489 ,  0.3819579 , -0.70777106, -0.59646434, -0.5215753 ,\n",
       "       -0.3045499 ,  0.317802  , -0.10606909,  0.7332442 ,  0.23039612,\n",
       "        0.5819155 ,  0.67548794, -0.44244   ,  0.49015892,  1.2374879 ,\n",
       "        1.6117889 , -0.70452935, -1.3834366 ,  0.5455318 , -0.47774336,\n",
       "       -0.30221483,  1.2695836 ,  0.08261449, -0.06846821, -0.34575793,\n",
       "       -0.01166613, -0.08309501, -0.24512067, -1.4202234 , -0.21453938,\n",
       "       -0.01749974,  0.532674  ,  0.03240364,  0.7314985 ,  0.7542217 ,\n",
       "        0.3194223 ,  0.40327644,  0.92769593,  0.13444327, -0.06761767,\n",
       "        0.5942332 ,  0.5847662 , -0.1290926 ,  0.42674312, -0.6286264 ,\n",
       "       -0.2011718 ,  0.1795953 , -0.9459404 , -0.14561294,  1.0732825 ,\n",
       "        0.03390206,  0.4360173 ,  0.36913094, -0.36894044, -0.04127573,\n",
       "        0.7354076 ,  0.89891994,  0.19702594,  0.10465066,  0.67545503,\n",
       "        1.3189462 , -0.03225214,  0.56462276, -0.05517858,  0.0669903 ,\n",
       "        0.26262724, -0.22712605, -0.32043585,  0.17950653, -0.94946176,\n",
       "        0.58012265, -0.31079987, -0.13215333,  0.69875133, -0.4284601 ,\n",
       "        0.34096807,  0.15945828,  0.56626314, -0.30807045,  0.06297124,\n",
       "       -1.3771136 ,  0.736695  ,  0.20599304,  0.02949284, -0.8130253 ,\n",
       "       -0.29478517, -0.78866994,  1.0525311 , -1.7157348 ,  0.28683156,\n",
       "       -0.14481379,  1.0261029 ,  0.47832143, -0.11128072, -0.00965944,\n",
       "        0.54457766, -0.57011914, -0.7482591 ,  0.43225595, -0.5884044 ,\n",
       "       -0.59367263, -0.08228329, -0.06523672, -0.18899883, -1.1340265 ,\n",
       "       -0.13636278,  0.18711679,  0.4292008 ,  0.26383325,  0.73787993,\n",
       "        0.3864968 , -0.7430518 , -0.7467955 , -0.37334296, -0.27219602,\n",
       "       -0.8958206 , -0.16032055, -0.02003494,  1.203577  ,  0.20990184,\n",
       "       -0.22263333,  0.6005229 ,  0.4878769 ,  0.51543593, -0.12946692,\n",
       "        0.955993  ,  0.44180268,  0.74949926,  0.65391856, -0.7037665 ,\n",
       "        1.024896  , -0.15966506,  0.74188155,  0.26052058, -0.45801368,\n",
       "        0.15109025, -0.27964124,  0.9352805 , -0.7212973 , -0.19114152,\n",
       "       -0.6542246 , -0.7147777 , -0.58016074, -0.27083984, -0.2604256 ,\n",
       "        0.32412556, -0.03127434,  0.43144783,  0.49833384,  0.24324515,\n",
       "       -0.2925886 ,  0.00864832, -0.38178873, -0.62986976, -0.48294404,\n",
       "        0.17592692, -0.70865214,  1.5598562 ,  0.48327532,  0.02904348,\n",
       "        0.61717474,  0.26674116, -0.228794  ,  0.6787887 , -0.71243346,\n",
       "        0.9588996 , -0.4940397 ,  0.60733306, -0.9985434 ,  1.0335959 ,\n",
       "       -0.36891925,  1.1326915 , -0.5450787 ,  0.58284706, -0.1227823 ,\n",
       "       -0.17596604, -0.47679046, -0.26974958, -0.7715043 ,  0.04885265,\n",
       "        0.17217098, -0.75331473, -0.5685737 ,  1.536126  ,  0.4445076 ,\n",
       "       -0.1575434 , -0.15655875,  0.4399099 , -0.69046396,  0.774001  ,\n",
       "        0.30270392, -0.22241029, -0.09173168,  0.15688995,  0.04080215,\n",
       "       -0.31110895,  1.1849279 ,  0.23584396, -1.0296304 ,  0.44196162,\n",
       "        0.6200966 , -0.08084225, -0.60729194, -0.31539637,  0.1587265 ,\n",
       "       -0.12261431, -0.6117755 ,  0.11648339, -0.0579564 ,  0.4803156 ,\n",
       "       -0.15719934,  0.19574535, -0.00232821, -0.14943735, -0.01411455,\n",
       "       -0.12279595,  1.2492999 , -0.6559454 ,  0.153063  ,  0.740412  ,\n",
       "        0.4355653 , -1.0361277 , -1.1869736 ,  0.5809791 , -0.34777576],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.wv['google']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((max_num_words, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i < max_num_words:\n",
    "        try:\n",
    "            embedding_vector = model2.wv[word]\n",
    "        except KeyError:\n",
    "            embedding_vector = None\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(np.sum(embedding_matrix, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 1147, 300)         300000    \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 344100)            0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                5505616   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 85        \n",
      "=================================================================\n",
      "Total params: 5,805,701\n",
      "Trainable params: 5,805,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_num_words, output_dim=embedding_dim, weights=[embedding_matrix], \n",
    "                    input_length=max_len, trainable=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1780/1780 [==============================] - 31s 18ms/sample - loss: 0.4199 - acc: 0.8781\n",
      "Epoch 2/5\n",
      "1780/1780 [==============================] - 30s 17ms/sample - loss: 0.1419 - acc: 0.9702s - loss: 0.1380 - - ETA: 1s - loss: 0.135\n",
      "Epoch 3/5\n",
      "1780/1780 [==============================] - 33s 18ms/sample - loss: 0.0900 - acc: 0.9837\n",
      "Epoch 4/5\n",
      "1780/1780 [==============================] - 32s 18ms/sample - loss: 0.0441 - acc: 0.9949\n",
      "Epoch 5/5\n",
      "1780/1780 [==============================] - 31s 17ms/sample - loss: 0.0453 - acc: 0.9927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23d08ede978>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_pad_sequ, dummy_y_train,\n",
    "            epochs=5,\n",
    "            batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_pad_sequ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8786516853932584"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(dummy_y_test, (predictions > 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find this notebook on https://github.com/arturzeitler/meetup/blob/master/embeddings2.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow version of the Keras code is going to be followed up soon."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
